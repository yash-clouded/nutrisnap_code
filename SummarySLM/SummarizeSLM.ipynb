{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b7886f1",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f239d38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             input_text  \\\n",
      "1348  Calories: 656, Protein: 44g, Fat: 9g, Carbs: 1...   \n",
      "742   Calories: 396, Protein: 15g, Fat: 32g, Carbs: ...   \n",
      "1967  Calories: 426, Protein: 54g, Fat: 77g, Carbs: ...   \n",
      "543   Calories: 218, Protein: 57g, Fat: 62g, Carbs: ...   \n",
      "1166  Calories: 599, Protein: 13g, Fat: 2g, Carbs: 6...   \n",
      "\n",
      "                                            target_text  \n",
      "1348  High-calorie meal, best taken during heavy act...  \n",
      "742   Moderate-calorie meal suitable for daily consu...  \n",
      "1967  Moderate-calorie meal suitable for daily consu...  \n",
      "543   Low-calorie meal ideal for light eating or sna...  \n",
      "1166  Moderate-calorie meal suitable for daily consu...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "def generate_food_entry():\n",
    "    calories = random.randint(100, 900)\n",
    "    protein = random.randint(1, 60)\n",
    "    fat = random.randint(1, 80)\n",
    "    carbs = random.randint(1, 120)\n",
    "    fiber = random.randint(0, 15)\n",
    "    sugar = random.randint(0, 50)\n",
    "    sodium = random.randint(50, 2000)\n",
    "\n",
    "    # Input text for model\n",
    "    input_text = (\n",
    "        f\"Calories: {calories}, Protein: {protein}g, Fat: {fat}g, \"\n",
    "        f\"Carbs: {carbs}g, Fiber: {fiber}g, Sugar: {sugar}g, Sodium: {sodium}mg\"\n",
    "    )\n",
    "\n",
    "    # Derived summary logic\n",
    "    summary_parts = []\n",
    "\n",
    "    # Calories insights\n",
    "    if calories < 300:\n",
    "        summary_parts.append(\"Low-calorie meal ideal for light eating or snacks.\")\n",
    "    elif calories < 600:\n",
    "        summary_parts.append(\"Moderate-calorie meal suitable for daily consumption.\")\n",
    "    else:\n",
    "        summary_parts.append(\"High-calorie meal, best taken during heavy activity or bulking phase.\")\n",
    "\n",
    "    # Protein insights\n",
    "    if protein > 30:\n",
    "        summary_parts.append(\"Excellent source of protein, supports muscle recovery.\")\n",
    "    elif protein > 15:\n",
    "        summary_parts.append(\"Contains adequate protein for balanced nutrition.\")\n",
    "    else:\n",
    "        summary_parts.append(\"Low in protein, may not be ideal for athletes.\")\n",
    "\n",
    "    # Fat insights\n",
    "    if fat > 50:\n",
    "        summary_parts.append(\"Very high in fat — consume sparingly.\")\n",
    "    elif fat > 25:\n",
    "        summary_parts.append(\"High-fat meal, suitable for keto or low-carb diets.\")\n",
    "    elif fat < 10:\n",
    "        summary_parts.append(\"Low-fat meal, heart-friendly option.\")\n",
    "\n",
    "    # Carbs and sugar insights\n",
    "    if carbs > 80:\n",
    "        summary_parts.append(\"Carb-rich meal, provides quick energy.\")\n",
    "    elif carbs < 30:\n",
    "        summary_parts.append(\"Low-carb meal, supports weight control.\")\n",
    "\n",
    "    if sugar > 20:\n",
    "        summary_parts.append(\"High in sugar, limit for diabetic or weight-conscious diets.\")\n",
    "    elif sugar < 5:\n",
    "        summary_parts.append(\"Low in sugar, suitable for low-glycemic diets.\")\n",
    "\n",
    "    # Fiber and sodium insights\n",
    "    if fiber >= 8:\n",
    "        summary_parts.append(\"Rich in fiber, promotes good digestion.\")\n",
    "    elif fiber < 3:\n",
    "        summary_parts.append(\"Low fiber content, pair with vegetables or whole grains.\")\n",
    "\n",
    "    if sodium > 1500:\n",
    "        summary_parts.append(\"Excess sodium — not recommended for hypertensive individuals.\")\n",
    "    elif sodium < 300:\n",
    "        summary_parts.append(\"Low sodium content, good for heart health.\")\n",
    "\n",
    "    # Combine insights into one coherent summary\n",
    "    target_text = \" \".join(summary_parts)\n",
    "    return {\"input_text\": input_text, \"target_text\": target_text}\n",
    "\n",
    "# Generate dataset\n",
    "dataset = [generate_food_entry() for _ in range(2000)]\n",
    "df = pd.DataFrame(dataset)\n",
    "df.to_csv(\"nutrition_summary_dataset.csv\", index=False)\n",
    "\n",
    "print(df.sample(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc266e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1800/1800 [00:00<00:00, 20291.96 examples/s]\n",
      "Map: 100%|██████████| 200/200 [00:00<00:00, 17866.35 examples/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'evaluation_strategy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 43\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {k: \u001b[38;5;28mround\u001b[39m(v \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m4\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Training arguments\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m training_args \u001b[38;5;241m=\u001b[39m \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./slm-recipe-summary\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_eval_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogging_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./logs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpredict_with_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpush_to_hub\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Trainer\u001b[39;00m\n\u001b[1;32m     58\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     59\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     60\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     66\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'evaluation_strategy'"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, TrainingArguments, Trainer\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"csv\", data_files=\"nutrition_summary_dataset.csv\")\n",
    "\n",
    "# Split into train/test\n",
    "dataset = dataset[\"train\"].train_test_split(test_size=0.1)\n",
    "\n",
    "# Tokenizer & model\n",
    "model_name = \"t5-small\"  # can replace with \"google/flan-t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# Preprocess\n",
    "max_input_length = 128\n",
    "max_target_length = 64\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = examples[\"input_text\"]\n",
    "    targets = examples[\"target_text\"]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "    labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "# Evaluation metric\n",
    "metric = evaluate.load(\"rouge\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    return {k: round(v * 100, 4) for k, v in result.items()}\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./slm-recipe-summary\",\n",
    "    learning_rate=2e-4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    predict_with_generate=True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
